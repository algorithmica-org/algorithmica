---
title: Система непересекающихся множеств
authors:
- Сергей Слотин
---

Система непересекающихся множеств (англ. *disjoint set union*) — структура данных, позволяющая объединять непересекающиеся множества и отвечать на разные запросы про них, например «находятся ли элементы $a$ и $b$ в одном множестве» и «чему равен размер данного множества».

Более формально, изначально имеется $n$ элементов, каждый из которых находится в отдельном (своём собственном) множестве. Структура поддерживает две базовые операции:

- Объединить два каких-либо множества.
- Запросить, в каком множестве сейчас находится указанный элемент.

Обе операции выполняются в среднем *почти* за $O(1)$ (но не совсем).

СНМ часто используется в графовых алгоритмах для хранения информации о связности компонент — например, в [алгоритме Краскала](/cs/spanning-trees/kruskal).

## Устройство структуры

Множества элементов мы будем хранить в виде деревьев: одно дерево соответствует одному множеству. Корень дерева — это представитель (лидер) множества. Для корней деревьев будем считать, что их предки — они сами.

![](../img/dsu.png)

Заведём массив `p`, в котором для каждого элемента мы храним номер его предка в дереве:

```c++
int p[maxn];

for (int i = 0; i < n; i++)
    p[i] = i;
```

Для запроса «в каком множестве элемент $v$» нужно подняться по ссылкам до корня:

```cpp
int leader(int v) {
    if (p[v] == v)
        return v;
    else
        return leader(p[v]);
}
```

Для объединения двух множеств нужно подвесить корень одного за корень другого:

```cpp
void unite(int a, int b) {
    a = leader(a), b = leader(b);
    p[a] = b;
}
```

К несчастью, в худшем случае такая реализация работает за $O(n)$ — можно построить «бамбук», подвешивая его $n$ раз за новую вершину. Сейчас мы это исправим.

### Оптимизации

Сначала привидем идеи оптимизации, а потом проанализируем, насколько хорошо они работают.

**Эвристика сжатия пути**. Оптимизируем работу функции `leader`. Давайте перед тем, как вернуть ответ, запишем его в `p` от текущей вершины, то есть переподвесим его за самую высокую.

```cpp
int leader(int v) {
    return (p[v] == v) ? v : p[v] = leader(p[v]);
}
```

Следующие две эвристики похожи по смыслу и стараются оптимизировать высоту дерева, выбирая оптимальный корень для переподвешивания.

**Ранговая эвристика**. Будем хранить для каждой вершины её *ранг* — высоту её поддерева. При объединении деревьев будем делать корнем нового дерева ту вершину, у которой ранг больше, и пересчитывать ранги (ранг у лидера должен увеличиться на единицу, если он совпадал с рангом другой вершины). Эта эвристика оптимизирует высоту дерева напрямую.

```cpp
void unite(int a, int b) {
    a = leader(a), b = leader(b);
    if (h[a] > h[b])
        swap(a, b);
    h[b] = max(h[b], h[a] + 1);
    p[a] = b;
}
```

**Весовая эвристика**. Будем вместо ранга хранить размеры поддеревьев для каждой вершины, а при объединении — подвешивать за более «тяжелую».

```cpp
void unite(int a, int b) {
    a = leader(a), b = leader(b);
    if (s[a] > s[b])
        swap(a, b);
    s[b] += s[a];
    p[a] = b;
}
```

Эвристики выбора вершины-лидера взаимоисключающие, но их можно использовать вместе со сжатием путей.

### Реализация

Финальная реализация, использующая весовую эвристику и эвристику сжатия путей:

```c++
int p[maxn], s[maxn];

int leader(int v) {
    return (p[v] == v) ? v : p[v] = leader(p[v]);
}

void unite(int a, int b) {
    a = leader(a), b = leader(b);
    if (s[a] > s[b])
        swap(a, b);
    s[b] += s[a];
    p[a] = b;
}

void init(n) {
    for (int i = 0; i < n; i++)
        p[i] = i, s[i] = 1;
}
```

Автор предпочитает именно весовую эвристику, потому что часто в задачах размеры компонент требуются сами по себе.

### Асимптотика

Эвристика сжатия путей улучшает асимптотику до $O(\log n)$ в среднем. Здесь используется именно амортизированная оценка — понятно, что в худшем случае нужно будет сжимать весь бамбук за $O(n)$.

![Сжатие пути после запроса $p(7)$](../img/path-compression.png)

Индукцией несложно показать, что весовая и ранговая эвристики ограничивают высоту дерева до $O(\log n)$, а соответственно и асимптотику нахождения корня тоже.

При использовании эвристики сжатия плюс весовой или ранговой асимптотика будет $O(a(n))$, где $a(n)$ — обратная функция Аккермана (очень медленно растущая функция, для всех адекватных чисел не превосходящая 4).

Тратить время на изучения доказательства или даже чтения статьи на Википедии про функцию Аккермана автор не рекомендует.

<!--

### Амортизированная стоимость $Get$

Проанализируем асимптотику операции $Get$ в случае, если мы применяем
обе эвристики. Пусть произошло $g$ операций типа $Get$ и $m$ операций
типа $Merge$, причём $g \\geq m$. Тогда суммарное время работы всех
$Get$ есть $O(g log^\*(m))$ (или, что то же самое, амортизированная
стоимость одного $Get$ есть $O(log^\*(m))$ ( [Что такое
$\\log^\*(x)$](https://ru.wikipedia.org/wiki/%D0%98%D1%82%D0%B5%D1%80%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D1%8B%D0%B9_%D0%BB%D0%BE%D0%B3%D0%B0%D1%80%D0%B8%D1%84%D0%BC)
).

Обозначим $d(v) \~-$ длину самого длинного пути вниз от вершины $v$.

Разобьём все операции $Get(v)$ на 3 типа:

1.  $v \~-$ корень или ребёнок корня в своём дереве. Таких операций
    будет не более $g$.
2.  $d(p(v)) \\leq C ^ {d(v)}$, где $C$ \~- некоторая констатнта,
    которую мы подберём позже. Такие запросы мы назовём быстро
    растущими, а ребро $(v, p(v)) \~-$ лёгким.
3.  $d(p(v)) \< C ^ {d(v)}$ $\~-$ такие запросы мы назовём медленно
    растущими, а соответствующее ребро $\~-$ тяжёлым.

На запросы первого типа мы ответим суммарно за $O(g)$.

Проанализируем быстро растущие запросы. Каждый раз в них $d(v)$
изменяется на $C^{d(v)}$. Поскольку $C$ не может быть больше
$log_2(m)$, каждая из этих операций выполнится за
$O(log^\*_C(log_2(m))) = O(log^\*(m))$.


### Лемма

Число вершин с $d(v) = i$ не превосходит $\frac{m}{2^i}$.

Доказательство этого утверждения (разумеется, по индукции) оставляется в
качестве упражнения читателю.

Проанализируем запросы 3 типа. Из леммы выше следует, что суммарное
количество операций в таких вызовах равно

$ \sum_{d=0}^{log_2(g)} \sum_{u: d(u) = u} C^d =
\sum_{d=0}^{log_2(g)} C^d \cdot \frac{m}{2^d}
m \cdot \sum_{d0}^{log_2(g)} \frac{C}{2} ^ d
$

Теперь, если мы хотим, чтобы получившееся выражение было $O(m)$, нужно
взять $C \in (e^\frac{1}{e}, 2)$.

Итак, мы получили, что суммарное время работы всех $Get$ есть $O(g) +
O(g \cdot \log^\star(m)) + O(m) = O(g \cdot \log^\star(m))$ (поскольку мы
предположили, что $g \ge m$).

### Асимптотика с обеими эвристиками (б/д)

Пусть нам поступаем $g$ запросов типа $GetRoot$ и $m$ запросов типа
$Merge$, причём $g \\leq n$. Тогда СНМ с обеими эвристиками выполнит их
за суммарное время $O((g+m) \\times \\alpha(g+m))$ [Что такое
$\\alpha(x)$](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%90%D0%BA%D0%BA%D0%B5%D1%80%D0%BC%D0%B0%D0%BD%D0%B0#%D0%9E%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%B0%D1%8F_%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F)

На практике эта теорема означает, что суммарное количество операций
будет не более, чем в 5 раз больше, чем число запросов.

-->
