---
title: Переобучение и валидация
---

Рассмотрим простую функцию $f(x) = 3x^3 - 2x^2 + x + \varepsilon(x)$:

Давайте попробуем приблизить эту функцию многочленом третьей степени:

![](../img/poly3.png)

Видно, что мы получили довольно хорошее приближение исходной функции

Попробуем увеличить степень нашей модели до шестнадцати:

![](../img/poly16.png)

Видно, что модель стала хуже предсказывать исходную зависимость, но при
этом на тренировочном множестве выдает идеальные ответы.

Мы столкнулись с проблемой **переобучения (overfitting)**.

## Разбиение на обучающую и тестовую выборку и кросс-валидация

Как узнать, находит ли исходную зависимость наша модель или
переобучается?

Обычно пользуются одним из двух подходов:

1.  **Разбиение на обучающую и тестовую выборку (train test split)**

    Прежде чем обучать модель, разобьем исходное тренировочное множество
    на обучающую и валидационную (тестовую) выборки.

    Теперь, если мы обучим модель на обучающей выборке, то сможем
    сравнить значение функции потерь на валидационной выборке, объекты
    из которой модель не видела при обучении, и на обучающей.

    Если эти значения сильно отличаются, то можно говорить о
    переобучении нашей модели.

2.  **Кросс-валидация** Разобьем исходное тренировочное множество на $k$
    примерно равных частей. Теперь поочередно обучим $k$ моделей на
    $k - 1$, каждый раз выкидывая новую часть. Если мы посчитаем функцию
    ошибки для каждой модели на частях, которые не были включены при
    обучении, а затем усредним, то получим более объективное значение
    функции ошибки.
